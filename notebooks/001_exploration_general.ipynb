{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# DroneDetect V2 - General Data Exploration\n",
    "\n",
    "**Dataset**: DroneDetect V2 (Swinney & Woods, 2021)  \n",
    "**Paper**: [The Effect of Real-World Interference on CNN Feature Extraction and ML Classification of UAS](https://doi.org/10.3390/aerospace8070179)  \n",
    "**Dataset**: [IEEE DataPort - DroneDetect V2](https://dx.doi.org/10.21227/6w92-0x42)\n",
    "\n",
    "This notebook analyzes the dataset structure and metadata:\n",
    "- File inventory and metadata validation\n",
    "- Class distribution analysis (drones, states, interference)\n",
    "- Identification of missing combinations\n",
    "- Data quality validation\n",
    "\n",
    "> **Note**: For detailed data collection methodology (hardware, flight conditions, drone specs), see [docs/methodology.md](../docs/methodology.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## DroneDetect V1 vs V2: Key Differences\n",
    "\n",
    "The original paper describes V1 with 500 samples per class across 4 interference conditions (CLEAN, WIFI, BLUETOOTH, BOTH). \n",
    "\n",
    "DroneDetect V2, publicly available on IEEE DataPort, differs: it contains **5 replicas** (index 0-4) per valid combination of drone/state/interference.\n",
    "\n",
    "Only **CLEAN** and **BOTH** interference conditions were retained for simplicity.\n",
    "\n",
    "The result is:\n",
    "\n",
    "- **195 recording files** (2-second raw IQ each)\n",
    "- **Expected combinations**: 7 drones x 3 states x 2 interferences = 42\n",
    "- **Actual combinations**: 39 (3 missing)\n",
    "- **Replicas per combination**: 5 (files indexed 0-4)\n",
    "\n",
    "This notebook analyzes a reduced version of DroneDetect V2 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import re\n",
    "import ipynbname\n",
    "\n",
    "# Import local modules\n",
    "from dronedetect import config, data_loader\n",
    "\n",
    "# Constants\n",
    "# SAMPLE_STRIDE: Downsampling factor for memory-efficient analysis\n",
    "# - Physical: Reduces 120M samples to ~1M samples (120M / 120 = 1M)\n",
    "# - Impact: Reduces sampling rate from 60 MHz to 500 kHz (60 MHz / 120 = 0.5 MHz)\n",
    "# - Temporal resolution: Increases sample interval from 16.67 ns to 2 μs\n",
    "# - Use case: Sufficient for amplitude/power statistics while reducing memory footprint 120x\n",
    "# - Limitation: May miss fast transients < 2 μs; not suitable for high-frequency spectral analysis\n",
    "SAMPLE_STRIDE = 120\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup figure saving\n",
    "NOTEBOOK_NAME = ipynbname.name()\n",
    "FIGURES_DIR = Path(\"../figures\") / NOTEBOOK_NAME\n",
    "\n",
    "def save_figure(fig) -> None:\n",
    "    \"\"\"Save plotly figure to PNG file using the figure's title as filename.\"\"\"\n",
    "    FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    title = fig.layout.title.text if fig.layout.title.text else \"untitled\"\n",
    "    filename = re.sub(r'[^\\w\\s-]', '', title).strip()\n",
    "    filename = re.sub(r'[\\s-]+', '_', filename)\n",
    "    filepath = FIGURES_DIR / f\"{filename}.png\"\n",
    "    try:\n",
    "        fig.write_image(str(filepath), width=1200, height=800)\n",
    "        print(f\"Saved: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save figure (kaleido required): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. Load Sample File\n",
    "\n",
    "Verify dataset access and inspect raw IQ data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample file to verify dataset access\n",
    "sample_file = config.DATA_DIR / \"CLEAN\" / \"AIR_ON\" / \"AIR_0000_00.dat\"\n",
    "\n",
    "if sample_file.exists():\n",
    "    iq_data = data_loader.load_raw_iq(sample_file)\n",
    "    \n",
    "    print(f\"\"\"Loading: {sample_file}\n",
    "\n",
    "=== IQ Data Inspection ===\n",
    "Shape: {iq_data.shape}\n",
    "Dtype: {iq_data.dtype}\n",
    "Total samples: {len(iq_data):,}\n",
    "Duration: {len(iq_data) / config.FS:.2f} seconds\n",
    "\n",
    "=== Value Range ===\n",
    "Real: [{iq_data.real.min():.4f}, {iq_data.real.max():.4f}]\n",
    "Imag: [{iq_data.imag.min():.4f}, {iq_data.imag.max():.4f}]\n",
    "NaN count: {np.isnan(iq_data).sum()}\n",
    "\n",
    "=== Data Format Explanation ===\n",
    "File storage: {config.RAW_SAMPLE_COUNT} float32 values (interleaved I/Q)\n",
    "Memory representation: {config.COMPLEX_SAMPLE_COUNT} complex64 samples\n",
    "Transformation: np.fromfile(dtype=float32, count=240M).view(complex64)\n",
    "  -> Each complex64 = 2 consecutive float32 (I + jQ)\n",
    "\n",
    "Sampling rate: {config.FS / 1e6:.0f} MHz\n",
    "Duration: {len(iq_data) / config.FS:.2f} seconds\n",
    "Total time-domain samples: {len(iq_data):,} complex\"\"\")\n",
    "else:\n",
    "    print(f\"\"\"File not found: {sample_file}\n",
    "Please verify the dataset path in config.py\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 2.1 Signal Amplitude Analysis by Drone (CLEAN/ON only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one file per drone (CLEAN/ON state)\n",
    "drone_codes = ['AIR', 'DIS', 'INS', 'MA1', 'MAV', 'MIN', 'PHA']\n",
    "amplitude_stats = []\n",
    "\n",
    "for drone in drone_codes:\n",
    "    file_path = config.DATA_DIR / \"BOTH\" / f\"{drone}_FY\" / f\"{drone}_1110_00.dat\"\n",
    "    if file_path.exists():\n",
    "        iq = data_loader.load_raw_iq(file_path)\n",
    "        # Sample 1M points for stats (faster)\n",
    "        sample = iq[::SAMPLE_STRIDE]  # 1M samples\n",
    "        amplitude = np.abs(sample)\n",
    "        \n",
    "        amplitude_stats.append({\n",
    "            'drone': drone,\n",
    "            'mean_amplitude': amplitude.mean(),\n",
    "            'std_amplitude': amplitude.std(),\n",
    "            'min': amplitude.min(),\n",
    "            'max': amplitude.max(),\n",
    "            'power_dbm': 10 * np.log10(np.mean(np.abs(sample)**2))\n",
    "        })\n",
    "\n",
    "# Visualize\n",
    "stats_df = pd.DataFrame(amplitude_stats)\n",
    "print(\"\"\"Signal amplitude statistics by drone (BOTH/FY):\"\"\")\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "fig = px.bar(stats_df, x='drone', y='mean_amplitude', error_y='std_amplitude',\n",
    "             title='Mean Signal Amplitude by Drone (BOTH/FY)')\n",
    "fig.update_yaxes(title_text=\"Mean Amplitude\")\n",
    "save_figure(fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 3. Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.DATA_DIR.exists():\n",
    "    df = data_loader.get_cached_metadata(force_refresh=True)\n",
    "    drone_counts = df['drone_code'].value_counts()\n",
    "    interference_counts = df['interference'].value_counts()\n",
    "    state_counts = df['state'].value_counts()\n",
    "    print(f\"Loaded {len(df)} files from cache: {config.METADATA_CACHE}\")\n",
    "else:\n",
    "    df = None\n",
    "    drone_counts = interference_counts = state_counts = None\n",
    "\n",
    "# Note: complete_df will be created in section 3.2 for combination-level analysis\n",
    "print(f\"\"\"\n",
    "============================================================\n",
    "METADATA LOADED\n",
    "============================================================\n",
    "Shape: {df.shape}\n",
    "Columns: {df.columns.tolist()}\n",
    "Purpose: One row per .dat file with full metadata (file_path, drone_code, state, interference, index)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic metadata information\n",
    "print(f\"\"\"============================================================\n",
    "DATASET OVERVIEW\n",
    "============================================================\n",
    "Total files: {len(df)}\n",
    "\n",
    "Drone codes: {sorted(df['drone_code'].unique())}\n",
    "States: {sorted(df['state'].unique())}\n",
    "Interference types: {sorted(df['interference'].unique())}\n",
    "\n",
    "============================================================\n",
    "DISTRIBUTION COUNTS\n",
    "============================================================\n",
    "\n",
    "By Drone:\n",
    "{drone_counts.to_dict()}\n",
    "\n",
    "By State:\n",
    "{state_counts.to_dict()}\n",
    "\n",
    "By Interference:\n",
    "{interference_counts.to_dict()}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### 3.1 Class Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distributions\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=3,\n",
    "    subplot_titles=('Drone Distribution', 'Interference Distribution', 'State Distribution')\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=drone_counts.index, y=drone_counts.values, name='Drone', marker_color='steelblue'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(x=interference_counts.index, y=interference_counts.values, name='Interference', marker_color='coral'),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(x=state_counts.index, y=state_counts.values, name='State', marker_color='seagreen'),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Drone Code\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Interference Type\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"State\", row=1, col=3)\n",
    "fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "\n",
    "fig.update_layout(title=\"Class Distributions\", height=400, showlegend=False)\n",
    "save_figure(fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### 3.1.1 File Distribution: CLEAN vs BOTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare CLEAN vs BOTH distribution\n",
    "interference_comparison = df.groupby(['drone_code', 'interference']).size().reset_index(name='count')\n",
    "\n",
    "fig = px.bar(interference_comparison, x='drone_code', y='count', color='interference',\n",
    "             barmode='group', title='File Count by Drone and Interference Type')\n",
    "fig.update_yaxes(title_text=\"File Count\")\n",
    "save_figure(fig)\n",
    "fig.show()\n",
    "\n",
    "print(f\"\"\"\n",
    "=== Summary ===\n",
    "CLEAN files: {len(df[df['interference'] == 'CLEAN'])}\n",
    "BOTH files: {len(df[df['interference'] == 'BOTH'])}\n",
    "\n",
    "Note: Slight imbalance due to missing combinations (DIS/HO/*, PHA/FY/CLEAN)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### 3.2 Missing Data Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE complete_df: combination-level DataFrame\n",
    "# Purpose: Analyze drone/state/interference combinations with file counts\n",
    "# Structure: One row per combination (not per file like df)\n",
    "\n",
    "# Identify missing combinations of drone/state/interference\n",
    "# Count files per combination\n",
    "pivot_data = df.groupby(['drone_code', 'state', 'interference']).size().reset_index(name='count')\n",
    "\n",
    "# Get unique values from actual data\n",
    "drones = sorted(df['drone_code'].unique())\n",
    "states = sorted(df['state'].unique())\n",
    "interferences = sorted(df['interference'].unique())\n",
    "\n",
    "# Generate all expected combinations\n",
    "all_combinations = list(product(drones, states, interferences))\n",
    "expected_df = pd.DataFrame(all_combinations, columns=['drone_code', 'state', 'interference'])\n",
    "\n",
    "# Merge with actual data\n",
    "complete_df = expected_df.merge(pivot_data, on=['drone_code', 'state', 'interference'], how='left')\n",
    "complete_df['count'] = complete_df['count'].fillna(0).astype(int)\n",
    "\n",
    "# Identify missing combinations\n",
    "missing_combinations = complete_df[complete_df['count'] == 0]\n",
    "\n",
    "print(f\"\"\"\n",
    "============================================================\n",
    "complete_df CREATED\n",
    "============================================================\n",
    "Shape: {complete_df.shape}\n",
    "Columns: {complete_df.columns.tolist()}\n",
    "Purpose: One row per drone/state/interference combination with file count\n",
    "  - Combinations with files: {len(complete_df[complete_df['count'] > 0])}\n",
    "  - Missing combinations: {len(complete_df[complete_df['count'] == 0])}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize heatmaps for each state with consistent color scale\n",
    "# Define consistent color scale range for all heatmaps (0 to 5 files per combination)\n",
    "color_min = 0\n",
    "color_max = 5\n",
    "\n",
    "for state in states:\n",
    "    state_df = complete_df[complete_df['state'] == state]\n",
    "    pivot_table = state_df.pivot(index='drone_code', columns='interference', values='count')\n",
    "    \n",
    "    fig = px.imshow(\n",
    "        pivot_table,\n",
    "        labels=dict(x=\"Interference\", y=\"Drone Code\", color=\"File Count\"),\n",
    "        title=f\"File Count Heatmap - State {state}\",\n",
    "        color_continuous_scale='RdYlGn',\n",
    "        zmin=color_min,\n",
    "        zmax=color_max,\n",
    "        text_auto=True,\n",
    "        aspect=\"auto\"\n",
    "    )\n",
    "    save_figure(fig)\n",
    "    fig.show()\n",
    "\n",
    "# Summary\n",
    "missing_summary = \"\\n\".join([f\"  - {row['drone_code']} / {row['state']} / {row['interference']}\"\n",
    "                             for _, row in missing_combinations.iterrows()]) if len(missing_combinations) > 0 else \"\"\n",
    "\n",
    "print(f\"\"\"\n",
    "==================================================\n",
    "MISSING COMBINATIONS SUMMARY\n",
    "==================================================\n",
    "Expected: {len(all_combinations)} combinations ({len(drones)} drones x {len(states)} states x {len(interferences)} interferences)\n",
    "Found: {len(pivot_data)} unique combinations\n",
    "Missing: {len(missing_combinations)} combinations\n",
    "\n",
    "Missing combinations:\n",
    "{missing_summary}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Note on Paper Documentation\n",
    "\n",
    "> **Note**: The DrondetectV1 paper does not discuss:\n",
    "> - Why certain combinations are missing (DIS/HO, PHA/FY/CLEAN)\n",
    "> - IQ value normalization or out-of-range handling\n",
    "> - File duration variations\n",
    ">\n",
    "> The paper focuses on interference impact on CNN classification, not dataset quality details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 3.3 Data Quality Validation\n",
    "\n",
    "This section validates the integrity and consistency of the DroneDetect V2 dataset:\n",
    "- **File integrity**: Verify sample counts, duration, and IQ value ranges\n",
    "- **Metadata consistency**: Ensure filenames match directory structure\n",
    "- **Index distribution**: Confirm all combinations have exactly 5 replicas\n",
    "- **IQ distributions**: Analyze signal characteristics and statistical properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### 3.3.1 File Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate file integrity and consistency for ALL files\n",
    "print(\"\"\"============================================================\n",
    "FILE INTEGRITY VALIDATION (ALL FILES)\n",
    "============================================================\"\"\")\n",
    "\n",
    "# Expected sample count per file\n",
    "EXPECTED_SAMPLES = 120_000_000  # 2 seconds at 60 MHz\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "# Check all files\n",
    "corrupted_files = []\n",
    "duration_issues = []\n",
    "sample_count_issues = []\n",
    "range_violations = []\n",
    "\n",
    "# Validate ALL files\n",
    "total_files = len(df)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if (idx + 1) % BATCH_SIZE == 0:\n",
    "        print(f\"  Validating file {idx + 1}/{total_files}...\")\n",
    "    try:\n",
    "        iq = data_loader.load_raw_iq(row['file_path'])\n",
    "        sample_count = len(iq)\n",
    "        i_min, i_max = iq.real.min(), iq.real.max()\n",
    "        q_min, q_max = iq.imag.min(), iq.imag.max()\n",
    "        duration = sample_count / config.FS\n",
    "        del iq\n",
    "\n",
    "        # Check sample count (should be exactly 120M)\n",
    "        if sample_count != EXPECTED_SAMPLES:\n",
    "            sample_count_issues.append((row['file_path'], sample_count))\n",
    "\n",
    "        # Check duration (should be ~2 seconds)\n",
    "        if abs(duration - 2.0) > 0.01:\n",
    "            duration_issues.append((row['file_path'], duration))\n",
    "\n",
    "        # Validate IQ value ranges (must be in [-1, 1] for normalized RF signals)\n",
    "        if i_min < -1.0 or i_max > 1.0 or q_min < -1.0 or q_max > 1.0:\n",
    "            range_violations.append({\n",
    "                'file': row['file_path'],\n",
    "                'i_range': (i_min, i_max),\n",
    "                'q_range': (q_min, q_max)\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        corrupted_files.append((row['file_path'], str(e)))\n",
    "\n",
    "print(f\"\"\"\n",
    "Validated {total_files} files (100%)\n",
    "\n",
    "=== Results ===\n",
    "Corrupted files: {len(corrupted_files)}\n",
    "Sample count issues (!= {EXPECTED_SAMPLES:,}): {len(sample_count_issues)}\n",
    "Duration issues (!= 2.0s): {len(duration_issues)}\"\"\")\n",
    "\n",
    "if corrupted_files:\n",
    "    corrupted_list = \"\\n\".join([f\"  - {f}: {err}\" for f, err in corrupted_files])\n",
    "    print(f\"\\nCorrupted files:\\n{corrupted_list}\")\n",
    "\n",
    "if sample_count_issues:\n",
    "    sample_issues_list = \"\\n\".join([f\"  - {f}: {count:,} samples\" for f, count in sample_count_issues])\n",
    "    print(f\"\\nSample count issues:\\n{sample_issues_list}\")\n",
    "\n",
    "if duration_issues:\n",
    "    duration_list = \"\\n\".join([f\"  - {f}: {dur:.3f}s\" for f, dur in duration_issues])\n",
    "    print(f\"\"\"\\nDuration issues:\n",
    "{duration_list}\n",
    "\n",
    "⚠️ Note: Files with duration < 2s will be handled in the preprocessing notebook.\n",
    "   Options: padding, exclusion, or variable-length windowing.\"\"\")\n",
    "\n",
    "if range_violations:\n",
    "    violations_list = \"\\n\".join([f\"  - {Path(v['file']).name}\\n    I: [{v['i_range'][0]:.4f}, {v['i_range'][1]:.4f}]\\n    Q: [{v['q_range'][0]:.4f}, {v['q_range'][1]:.4f}]\"\n",
    "                                 for v in range_violations[:10]])\n",
    "    more_msg = f\"  ... and {len(range_violations) - 10} more files\" if len(range_violations) > 10 else \"\"\n",
    "    print(f\"\"\"\\nFiles with IQ values outside [-1, 1]: {len(range_violations)}\n",
    "\n",
    "Files violating [-1, 1] range:\n",
    "{violations_list}\n",
    "{more_msg}\"\"\")\n",
    "else:\n",
    "    print(\"-> All files have IQ values within expected range [-1, 1]\")\n",
    "\n",
    "\n",
    "# Store validation results for conclusion\n",
    "validation_results = {\n",
    "    'total_files': total_files,\n",
    "    'corrupted': len(corrupted_files),\n",
    "    'sample_issues': len(sample_count_issues),\n",
    "    'duration_issues': len(duration_issues)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### 3.3.2 Metadata Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate metadata consistency: filename codes vs directory hierarchy\n",
    "print(\"\"\"\n",
    "============================================================\n",
    "METADATA CONSISTENCY VALIDATION\n",
    "============================================================\"\"\")\n",
    "\n",
    "inconsistencies = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    file_path = Path(row['file_path'])\n",
    "    \n",
    "    # Extract info from directory structure\n",
    "    # Expected: .../INTERFERENCE/DRONE_STATE/DRONE_XXXX_YY.dat\n",
    "    dir_interference = file_path.parent.parent.name  # CLEAN or BOTH\n",
    "    dir_drone_state = file_path.parent.name  # e.g., AIR_ON\n",
    "    \n",
    "    # Parse drone and state from directory name\n",
    "    dir_parts = dir_drone_state.split('_')\n",
    "    if len(dir_parts) >= 2:\n",
    "        dir_drone = dir_parts[0]\n",
    "        dir_state = dir_parts[1]\n",
    "    else:\n",
    "        dir_drone = dir_parts[0]\n",
    "        dir_state = 'UNKNOWN'\n",
    "    \n",
    "    # Compare with extracted metadata\n",
    "    if row['drone_code'] != dir_drone:\n",
    "        inconsistencies.append((row['file_path'], 'drone_code', row['drone_code'], dir_drone))\n",
    "    if row['state'] != dir_state:\n",
    "        inconsistencies.append((row['file_path'], 'state', row['state'], dir_state))\n",
    "    if row['interference'] != dir_interference:\n",
    "        inconsistencies.append((row['file_path'], 'interference', row['interference'], dir_interference))\n",
    "\n",
    "if inconsistencies:\n",
    "    inconsist_list = \"\\n\".join([f\"  - {Path(f).name}\\n    {field}: extracted='{extracted}' vs directory='{from_dir}'\"\n",
    "                                for f, field, extracted, from_dir in inconsistencies[:5]])\n",
    "    more_inconsist = f\"  ... and {len(inconsistencies) - 5} more inconsistencies\" if len(inconsistencies) > 5 else \"\"\n",
    "    print(f\"\"\"\n",
    "Files checked: {len(df)}\n",
    "Inconsistencies found: {len(inconsistencies)}\n",
    "\n",
    "Inconsistencies (showing first 5):\n",
    "{inconsist_list}\n",
    "{more_inconsist}\n",
    "\n",
    "============================================================\n",
    "CONVENTION ADOPTED\n",
    "============================================================\n",
    "This code uses filenames (MA1/MAV) as ground truth, not directory names (MP1/MP2).\n",
    "Reason: Filenames match DJI official model codes (Mavic Air, Mavic Pro).\n",
    "The paper aerospace-08-00179-v2.pdf uses full names, not abbreviated codes.\"\"\")\n",
    "else:\n",
    "    print(f\"\"\"\n",
    "Files checked: {len(df)}\n",
    "Inconsistencies found: {len(inconsistencies)}\n",
    "\n",
    "-> All metadata extracted from filenames matches directory hierarchy\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### 3.3.3 Index Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze index distribution\n",
    "index_counts = df['index'].value_counts().sort_index()\n",
    "expected_indices = set(range(5))  # 0-4\n",
    "actual_indices = set(df['index'].unique())\n",
    "missing_indices = expected_indices - actual_indices\n",
    "\n",
    "missing_idx_msg = f\"\\nWarning: Missing indices: {missing_indices}\" if missing_indices else \"\\n-> All expected indices (0-4) are present\"\n",
    "\n",
    "# Verify all valid combinations have exactly 5 replicas\n",
    "valid_combinations = complete_df[complete_df['count'] > 0]\n",
    "all_have_5 = (valid_combinations['count'] == 5).all()\n",
    "\n",
    "non_5_msg = \"\"\n",
    "if not all_have_5:\n",
    "    non_5 = valid_combinations[valid_combinations['count'] != 5]\n",
    "    non_5_msg = \"\\nCombinations with != 5 replicas:\\n\" + \"\\n\".join(\n",
    "        [f\"  - {row['drone_code']}/{row['state']}/{row['interference']}: {row['count']} files\"\n",
    "         for _, row in non_5.iterrows()])\n",
    "\n",
    "print(f\"\"\"\n",
    "============================================================\n",
    "INDEX DISTRIBUTION\n",
    "============================================================\n",
    "\n",
    "Index distribution (expected: 5 files per combination):\n",
    "{index_counts.to_dict()}\n",
    "{missing_idx_msg}\n",
    "\n",
    "=== REPLICA UNIFORMITY ===\n",
    "All valid combinations have exactly 5 replicas: {all_have_5}{non_5_msg}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "##### 3.3.3.1 Replica Reproducibility Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility check: Load 5 replicas of a single combination (BOTH/FY)\n",
    "# We use the first available drone with BOTH/FY combination\n",
    "test_combination = complete_df[(complete_df['interference'] == 'BOTH') &\n",
    "                                (complete_df['state'] == 'FY') &\n",
    "                                (complete_df['count'] > 0)].iloc[0]\n",
    "\n",
    "test_drone = test_combination['drone_code']\n",
    "print(f\"\"\"============================================================\n",
    "REPLICA REPRODUCIBILITY: {test_drone} / FY / BOTH\n",
    "============================================================\"\"\")\n",
    "\n",
    "replica_stats = []\n",
    "for idx in range(5):\n",
    "    files = df[(df['drone_code'] == test_drone) &\n",
    "               (df['state'] == 'FY') &\n",
    "               (df['interference'] == 'BOTH') &\n",
    "               (df['index'] == idx)]\n",
    "    \n",
    "    if len(files) > 0:\n",
    "        file_path = files.iloc[0]['file_path']\n",
    "        iq = data_loader.load_raw_iq(file_path)\n",
    "        # Sample 1M points\n",
    "        sample = iq[::SAMPLE_STRIDE]\n",
    "        \n",
    "        replica_stats.append({\n",
    "            'replica': idx,\n",
    "            'mean_real': sample.real.mean(),\n",
    "            'std_real': sample.real.std(),\n",
    "            'mean_imag': sample.imag.mean(),\n",
    "            'std_imag': sample.imag.std(),\n",
    "            'range_real': (sample.real.min(), sample.real.max()),\n",
    "            'range_imag': (sample.imag.min(), sample.imag.max())\n",
    "        })\n",
    "\n",
    "replica_df = pd.DataFrame(replica_stats)\n",
    "intra_std = replica_df[['mean_real', 'std_real', 'mean_imag', 'std_imag']].std()\n",
    "\n",
    "print(f\"\"\"\n",
    "Replica statistics (sampled 1M points each):\n",
    "{replica_df.to_string(index=False)}\n",
    "\n",
    "=== INTRA-REPLICA VARIABILITY ===\n",
    "Standard deviation of means across replicas:\n",
    "  Real: {intra_std['mean_real']:.6f}\n",
    "  Imag: {intra_std['mean_imag']:.6f}\n",
    "\n",
    "Interpretation: Low variability indicates consistent recording conditions across replicas.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility check: Load 5 replicas of a single combination (CLEAN/FY)\n",
    "# We use the first available drone with CLEAN/FY combination\n",
    "test_combination = complete_df[(complete_df['interference'] == 'CLEAN') &\n",
    "                                (complete_df['state'] == 'FY') &\n",
    "                                (complete_df['count'] > 0)].iloc[0]\n",
    "\n",
    "test_drone = test_combination['drone_code']\n",
    "print(f\"\"\"============================================================\n",
    "REPLICA REPRODUCIBILITY: {test_drone} / FY / CLEAN\n",
    "============================================================\"\"\")\n",
    "\n",
    "replica_stats = []\n",
    "for idx in range(5):\n",
    "    files = df[(df['drone_code'] == test_drone) &\n",
    "               (df['state'] == 'FY') &\n",
    "               (df['interference'] == 'CLEAN') &\n",
    "               (df['index'] == idx)]\n",
    "    \n",
    "    if len(files) > 0:\n",
    "        file_path = files.iloc[0]['file_path']\n",
    "        iq = data_loader.load_raw_iq(file_path)\n",
    "        # Sample 1M points\n",
    "        sample = iq[::SAMPLE_STRIDE]\n",
    "        \n",
    "        replica_stats.append({\n",
    "            'replica': idx,\n",
    "            'mean_real': sample.real.mean(),\n",
    "            'std_real': sample.real.std(),\n",
    "            'mean_imag': sample.imag.mean(),\n",
    "            'std_imag': sample.imag.std(),\n",
    "            'range_real': (sample.real.min(), sample.real.max()),\n",
    "            'range_imag': (sample.imag.min(), sample.imag.max())\n",
    "        })\n",
    "\n",
    "replica_df = pd.DataFrame(replica_stats)\n",
    "intra_std = replica_df[['mean_real', 'std_real', 'mean_imag', 'std_imag']].std()\n",
    "\n",
    "print(f\"\"\"\n",
    "Replica statistics (sampled 1M points each):\n",
    "{replica_df.to_string(index=False)}\n",
    "\n",
    "=== INTRA-REPLICA VARIABILITY ===\n",
    "Standard deviation of means across replicas:\n",
    "  Real: {intra_std['mean_real']:.6f}\n",
    "  Imag: {intra_std['mean_imag']:.6f}\n",
    "\n",
    "Interpretation: Low variability indicates consistent recording conditions across replicas.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "#### 3.3.4 IQ Value Distributions\n",
    "\n",
    "**Sampling strategy**: We sample 100,000 points (0.08% of 120M samples) for visualization because:\n",
    "1. Reduces rendering time (plotly performance)\n",
    "2. Avoids overplotting (120M points would appear as solid blob)\n",
    "3. Maintains statistical representation (random sampling)\n",
    "4. The full signal range is [-0.99, 0.99] (verified in section 2), but most samples are concentrated near origin (weak signal baseline)\n",
    "5. Extreme values (peaks) are rare and may not appear in this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze IQ value distributions - AIR_0000_00.dat (CLEAN/ON)\n",
    "sample_file = config.DATA_DIR / \"CLEAN\" / \"AIR_ON\" / \"AIR_0000_00.dat\"\n",
    "\n",
    "if sample_file.exists():\n",
    "    print(f\"\"\"\n",
    "============================================================\n",
    "IQ VALUE DISTRIBUTION\n",
    "File: {sample_file.name} ({sample_file.parent.parent.name} / {sample_file.parent.name.split('_')[1]})\n",
    "============================================================\"\"\")\n",
    "    \n",
    "    # Load IQ data for this specific file\n",
    "    iq_data = data_loader.load_raw_iq(sample_file)\n",
    "    \n",
    "    # Create histograms for I and Q components\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('In-phase (I) Distribution', 'Quadrature (Q) Distribution')\n",
    "    )\n",
    "    \n",
    "    # Sample 100k points for faster plotting\n",
    "    np.random.seed(42)\n",
    "    sample_indices = np.random.choice(len(iq_data), size=min(100000, len(iq_data)), replace=False)\n",
    "    i_sample = iq_data.real[sample_indices]\n",
    "    q_sample = iq_data.imag[sample_indices]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=i_sample, nbinsx=100, name='I', marker_color='steelblue'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=q_sample, nbinsx=100, name='Q', marker_color='coral'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Amplitude\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Amplitude\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"IQ Component Distributions CLEAN ON - {sample_file.name}\",\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    save_figure(fig)\n",
    "    fig.show()\n",
    "    \n",
    "    # IQ scatter plot (constellation diagram)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scattergl(\n",
    "        x=i_sample,\n",
    "        y=q_sample,\n",
    "        mode='markers',\n",
    "        marker=dict(size=1, opacity=0.3, color='steelblue'),\n",
    "        name='IQ Samples'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"IQ Constellation Diagram CLEAN ON - {sample_file.name}\",\n",
    "        xaxis_title=\"In-phase (I)\",\n",
    "        yaxis_title=\"Quadrature (Q)\",\n",
    "        height=600,\n",
    "        width=600\n",
    "    )\n",
    "    save_figure(fig)\n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"\"\"\n",
    "I component: mean={i_sample.mean():.4f}, std={i_sample.std():.4f}\n",
    "Q component: mean={q_sample.mean():.4f}, std={q_sample.std():.4f}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
