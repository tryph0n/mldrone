{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DroneDetect V2 - Raw IQ Feature Extraction\n",
    "\n",
    "## Overview\n",
    "This notebook implements Raw IQ (downsampled) feature extraction for RF-based drone classification using deep learning architectures.\n",
    "\n",
    "## Methodology\n",
    "We follow a **two-stage pipeline**: (1) IQ Downsampling → (2) Deep Learning Training (RF-UAVNet)\n",
    "\n",
    "The IQ extraction process:\n",
    "1. Loads raw I/Q samples from .dat files (60 MHz sampling rate)\n",
    "2. **Normalizes per-file** (Min-max [0,1]) before segmentation - **DIFFERENT from PSD/Spectrogram!**\n",
    "3. Segments continuous signals into fixed-duration windows (20ms)\n",
    "4. **Downsamples** from ~1.2M to 10k samples via linear interpolation\n",
    "5. Saves complex IQ data as (2, 10000) = [real, imag]\n",
    "\n",
    "## Why Raw IQ Features?\n",
    "\n",
    "**Raw IQ**: Preserves phase information and signal structure for end-to-end learning. Enables neural networks to discover representations beyond hand-crafted features.\n",
    "\n",
    "**Advantages**:\n",
    "- Preserves full signal information (magnitude + phase)\n",
    "- No information loss from feature engineering\n",
    "- End-to-end learnable representations\n",
    "- Matches RF-UAVNet architecture\n",
    "\n",
    "## Parameter Selection\n",
    "\n",
    "**Aligned with RF-UAVNet reference:**\n",
    "- **Segment duration**: **20ms**\n",
    "- **Downsampled size**: **10,000 samples** (from ~1.2M)\n",
    "- **Normalization**: **Min-max [0,1] per-file** - Matches RadioML2016 protocol\n",
    "- **Format**: **(2, 10000)** - [I channel, Q channel]\n",
    "- **Downsampling method**: **Linear interpolation** - Preserves signal shape\n",
    "\n",
    "### Critical Difference: Min-Max Normalization\n",
    "\n",
    "Unlike PSD/Spectrogram (Z-score), IQ uses **min-max [0,1]** normalization:\n",
    "- Prevents negative values (important for some architectures)\n",
    "- Bounded range [0,1] stabilizes training\n",
    "- Matches RF-UAVNet paper implementation\n",
    "- Per-channel normalization (I and Q independently)\n",
    "\n",
    "## Downstream Usage\n",
    "\n",
    "IQ features are consumed by:\n",
    "- `05_training_rfuavnet_COLAB.ipynb` - RF-UAVNet deep learning\n",
    "\n",
    "## Reference Alignment\n",
    "Parameters verified against REFERENTIEL_DRONEDETECT_RFCLASSIFICATION.md Section 3.2 and arXiv:2308.11833.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import gc\n",
    "import psutil\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Any, List\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import zipfile\n",
    "\n",
    "from dronedetect import config, data_loader, preprocessing, features\n",
    "\n",
    "# Memory monitoring utility\n",
    "\n",
    "def get_memory_mb():\n",
    "    return psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024\n",
    "\n",
    "\n",
    "# Create output directory\n",
    "config.FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Initial memory: {get_memory_mb():.0f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications\n",
    "\n",
    "All preprocessing parameters defined here for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREPROCESSING SPECIFICATIONS\n",
    "# =============================================================================\n",
    "# All parameters controlling feature extraction defined here for reproducibility.\n",
    "\n",
    "# --- Signal Segmentation ---\n",
    "SEGMENT_DURATION_MS = 20        # Window length (config.DEFAULT_SEGMENT_MS)\n",
    "                                 # RFClassification results: 10ms→20ms→50ms improves 76.9%→83.6%→89.4%\n",
    "\n",
    "# --- Feature Extraction Parameters ---\n",
    "N_FFT = 1024                     # FFT size - Reference: REFERENTIEL Section 1.2.1 (nperseg=1024)\n",
    "                                 # Frequency resolution = 60MHz/1024 ≈ 58.6 kHz/bin\n",
    "\n",
    "SPECTROGRAM_SIZE = (224, 224)    # Output image dimensions (config.DEFAULT_SPEC_SIZE)\n",
    "                                 # Matches VGG16/ResNet input for transfer learning\n",
    "\n",
    "IQ_DOWNSAMPLE_TARGET = 10000     # Downsampled IQ samples (config.DEFAULT_IQ_DOWNSAMPLE)\n",
    "                                 # Original: ~1.2M samples/segment → 10k for memory efficiency\n",
    "\n",
    "# --- Batch Processing ---\n",
    "BATCH_SIZE = 2                  # Files per batch (adjust based on available RAM)\n",
    "\n",
    "# --- Dataset Info ---\n",
    "SAMPLING_RATE_MHZ = 60           # DroneDetect V2 sampling frequency\n",
    "EXPECTED_SEGMENTS_PER_FILE = 100 # Approx (2s recording / 20ms window)\n",
    "\n",
    "print(\"Specifications loaded:\")\n",
    "print(f\"  Segment: {SEGMENT_DURATION_MS}ms | FFT: {N_FFT} | Batch: {BATCH_SIZE} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Architecture\n",
    "\n",
    "Modular pipeline system for flexible feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREPROCESSING ARCHITECTURE\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "class PreprocessingStep:\n",
    "    \"\"\"Base class for preprocessing steps.\"\"\"\n",
    "    \n",
    "    def process(self, segment: np.ndarray) -> Any:\n",
    "        \"\"\"Process a signal segment.\n",
    "        \n",
    "        Args:\n",
    "            segment: Input signal segment\n",
    "            \n",
    "        Returns:\n",
    "            Processed output (type depends on step)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "\n",
    "class PSDStep(PreprocessingStep):\n",
    "    \"\"\"Power Spectral Density via Welch method with per-sample normalization.\"\"\"\n",
    "    \n",
    "    def __init__(self, nfft=1024):\n",
    "        self.nfft = nfft\n",
    "    \n",
    "    def process(self, segment):\n",
    "        _, psd = features.compute_psd(segment, nfft=self.nfft)\n",
    "        # Per-sample normalization (reference: REFERENTIEL Section 1.3.1, line 220)\n",
    "        # Division by max with zero-protection\n",
    "        psd_max = np.max(psd)\n",
    "        if psd_max < 1e-15:  # Essentially zero power\n",
    "            return np.zeros_like(psd)\n",
    "        return psd / psd_max\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"PSDStep(nfft={self.nfft})\"\n",
    "\n",
    "\n",
    "class SpectrogramStep(PreprocessingStep):\n",
    "    \"\"\"Spectrogram via STFT + resize.\"\"\"\n",
    "    \n",
    "    def __init__(self, target_size=(224, 224)):\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def process(self, segment):\n",
    "        return features.compute_spectrogram(segment, target_size=self.target_size)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"SpectrogramStep(size={self.target_size})\"\n",
    "\n",
    "\n",
    "class DownsampleIQStep(PreprocessingStep):\n",
    "    \"\"\"Downsample IQ via linear interpolation.\"\"\"\n",
    "    \n",
    "    def __init__(self, target_samples=10000):\n",
    "        self.target_samples = target_samples\n",
    "    \n",
    "    def process(self, segment):\n",
    "        return preprocessing.downsample_iq(segment, target_samples=self.target_samples)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"DownsampleIQStep(n={self.target_samples})\"\n",
    "\n",
    "\n",
    "class FeaturePipeline:\n",
    "    \"\"\"Pipeline orchestrating multiple preprocessing steps.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, steps: List[PreprocessingStep]):\n",
    "        \"\"\"Initialize pipeline.\n",
    "        \n",
    "        Args:\n",
    "            name: Pipeline identifier (used for output filename)\n",
    "            steps: List of preprocessing steps to apply in order\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.steps = steps\n",
    "    \n",
    "    def process_segment(self, segment: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply all steps sequentially.\n",
    "        \n",
    "        Args:\n",
    "            segment: Input signal segment\n",
    "            \n",
    "        Returns:\n",
    "            Final processed features\n",
    "        \"\"\"\n",
    "        data = segment\n",
    "        for step in self.steps:\n",
    "            data = step.process(data)\n",
    "        return data\n",
    "    \n",
    "    def get_output_filename(self) -> str:\n",
    "        \"\"\"Get output filename for this pipeline.\"\"\"\n",
    "        return f\"{self.name}_features.npz\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        steps_str = ' → '.join([str(s) for s in self.steps])\n",
    "        return f\"Pipeline({self.name}): {steps_str}\"\n",
    "\n",
    "\n",
    "print(\"Preprocessing architecture loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Configuration\n",
    "\n",
    "Define preprocessing pipelines for different feature types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PIPELINE CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Single pipeline for IQ features\n",
    "pipeline = FeaturePipeline(\n",
    "    name='iq',\n",
    "    steps=[DownsampleIQStep(target_samples=IQ_DOWNSAMPLE_TARGET)]\n",
    ")\n",
    "\n",
    "print(f\"Configured pipeline: {pipeline}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scan Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_loader.get_dataset_metadata(config.DATA_DIR)\n",
    "print(f\"Total files: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Features (Batch Processing)\n",
    "\n",
    "Process files in batches to avoid memory saturation. Features are written progressively to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BATCH PROCESSING - Extract Features\n",
    "# =============================================================================\n",
    "\n",
    "# Initialize label encoders\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "drone_encoder = LabelEncoder()\n",
    "interference_encoder = LabelEncoder()\n",
    "state_encoder = LabelEncoder()\n",
    "\n",
    "drone_encoder.fit(df['drone_code'].unique())\n",
    "interference_encoder.fit(df['interference'].unique())\n",
    "state_encoder.fit(df['state'].unique())\n",
    "\n",
    "print(f\"Label encoders initialized\")\n",
    "print(f\"  Drones: {drone_encoder.classes_}\")\n",
    "print(f\"  Interference: {interference_encoder.classes_}\")\n",
    "print(f\"  States: {state_encoder.classes_}\")\n",
    "\n",
    "# Batch processing\n",
    "batch_files = []\n",
    "batch_idx = 0\n",
    "\n",
    "for batch_start in tqdm(range(0, len(df), BATCH_SIZE), desc=\"Processing batches\"):\n",
    "    batch_df = df.iloc[batch_start:batch_start + BATCH_SIZE]\n",
    "\n",
    "    # Storage for current batch\n",
    "    batch_features = []\n",
    "    labels_batch = []\n",
    "    file_ids_batch = []\n",
    "\n",
    "    print(f\"\\nBatch {batch_idx}: files {batch_start}-{batch_start + len(batch_df)}\")\n",
    "\n",
    "    for idx, row in batch_df.iterrows():\n",
    "        try:\n",
    "            # Load IQ data\n",
    "            iq_data = data_loader.load_raw_iq(row['file_path'])\n",
    "\n",
    "            # CRITICAL: Min-max [0,1] normalization for IQ/RF-UAVNet\n",
    "            iq_normalized = preprocessing.normalize_minmax(iq_data)\n",
    "\n",
    "            # Segment into 20ms windows\n",
    "            segments = preprocessing.segment_signal(iq_normalized, segment_ms=SEGMENT_DURATION_MS)\n",
    "\n",
    "            # Process each segment through pipeline\n",
    "            for seg in segments:\n",
    "                seg = seg.copy()  # Break view to allow memory release\n",
    "\n",
    "                # Extract features\n",
    "                feature_output = pipeline.process_segment(seg)\n",
    "                batch_features.append(feature_output)\n",
    "\n",
    "                # Encode labels\n",
    "                labels_batch.append({\n",
    "                    'drone': drone_encoder.transform([row['drone_code']])[0],\n",
    "                    'interference': interference_encoder.transform([row['interference']])[0],\n",
    "                    'state': state_encoder.transform([row['state']])[0]\n",
    "                })\n",
    "                file_ids_batch.append(idx)\n",
    "\n",
    "                del seg\n",
    "\n",
    "            # Free memory\n",
    "            del iq_data, iq_normalized, segments\n",
    "            gc.collect()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {row['file_path']}: {e}\")\n",
    "            raise Exception from e\n",
    "\n",
    "    # Save batch to disk\n",
    "    batch_file = config.FEATURES_DIR / f'batch_{batch_idx:03d}.npz'\n",
    "    np.savez_compressed(\n",
    "        batch_file,\n",
    "        iq=np.array(batch_features),\n",
    "        labels=np.array(labels_batch, dtype=object),\n",
    "        file_ids=np.array(file_ids_batch, dtype=np.int32)\n",
    "    )\n",
    "    batch_files.append(batch_file)\n",
    "\n",
    "    print(f\"  Saved {len(batch_features)} samples to {batch_file.name}\")\n",
    "    print(f\"  Memory: {get_memory_mb():.0f} MB\")\n",
    "\n",
    "    # Clean batch data\n",
    "    del batch_features, labels_batch, file_ids_batch\n",
    "    gc.collect()\n",
    "\n",
    "    batch_idx += 1\n",
    "\n",
    "print(f\"\\nBatch processing complete: {len(batch_files)} batches saved\")\n",
    "print(f\"Memory: {get_memory_mb():.0f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merge Batches into Final Files\n",
    "\n",
    "Combine all batch files into single feature files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OPTIMIZED BATCH MERGING (Disk-backed, ZERO RAM accumulation)\n",
    "# =============================================================================\n",
    "print(\"Merging batches (disk-backed memmap)...\")\n",
    "\n",
    "MERGE_CHUNK_SIZE = 5  # Process N batches at a time\n",
    "\n",
    "\n",
    "def merge_pipeline_chunked(pipeline_name, batch_files, chunk_size=5):\n",
    "    \"\"\"Merge batches for a single pipeline using disk-backed memory mapping.\n",
    "\n",
    "    This approach prevents memory saturation by:\n",
    "    1. Writing directly to disk via memmap (NO RAM accumulation)\n",
    "    2. Processing one pipeline at a time\n",
    "    3. Pre-allocating final array size\n",
    "    4. Keeping memmap for direct npz save (no RAM load)\n",
    "\n",
    "    Args:\n",
    "        pipeline_name: Name of pipeline ('psd', 'spectrogram', 'iq')\n",
    "        batch_files: List of batch file paths\n",
    "        chunk_size: Number of batches to process simultaneously\n",
    "\n",
    "    Returns:\n",
    "        dict with memmap + metadata (labels stay in RAM - small)\n",
    "    \"\"\"\n",
    "    print(f\"\\n[{pipeline_name}] Processing {len(batch_files)} batches (disk-backed)...\")\n",
    "\n",
    "    # STEP 1: Calculate total size by scanning batches\n",
    "    print(f\"[{pipeline_name}] Scanning batches to determine size...\")\n",
    "    total_samples = 0\n",
    "    feature_shape = None\n",
    "\n",
    "    for batch_file in batch_files:\n",
    "        data = np.load(batch_file, allow_pickle=True)\n",
    "        batch_features = data[pipeline_name]\n",
    "        total_samples += len(batch_features)\n",
    "        if feature_shape is None:\n",
    "            feature_shape = batch_features.shape[1:]  # (1024,) or (224,224,3)\n",
    "        del data\n",
    "\n",
    "    print(f\"[{pipeline_name}] Total samples: {total_samples}, feature shape: {feature_shape}\")\n",
    "\n",
    "    # STEP 2: Create memmap file (writes directly to disk)\n",
    "    memmap_file = config.FEATURES_DIR / f'{pipeline_name}_features_X.mmap'\n",
    "    final_shape = (total_samples,) + feature_shape\n",
    "\n",
    "    print(f\"[{pipeline_name}] Creating memmap: {final_shape} ({np.prod(final_shape)*4/1e9:.2f} GB)\")\n",
    "    X_memmap = np.memmap(memmap_file, dtype='float32', mode='w+', shape=final_shape)\n",
    "\n",
    "    # Storage for labels (small, can stay in RAM)\n",
    "    all_drone_labels = []\n",
    "    all_interference_labels = []\n",
    "    all_state_labels = []\n",
    "    all_file_ids = []\n",
    "\n",
    "    # STEP 3: Fill memmap progressively\n",
    "    write_offset = 0\n",
    "\n",
    "    for chunk_start in tqdm(range(0, len(batch_files), chunk_size), desc=f\"{pipeline_name} chunks\"):\n",
    "        chunk_batch_files = batch_files[chunk_start:chunk_start + chunk_size]\n",
    "\n",
    "        for batch_file in chunk_batch_files:\n",
    "            data = np.load(batch_file, allow_pickle=True)\n",
    "\n",
    "            # Write features directly to disk\n",
    "            batch_features = data[pipeline_name]\n",
    "            n_samples = len(batch_features)\n",
    "            X_memmap[write_offset:write_offset + n_samples] = batch_features\n",
    "            write_offset += n_samples\n",
    "\n",
    "            # Collect labels (small)\n",
    "            labels = data['labels']\n",
    "            all_drone_labels.extend([label['drone'] for label in labels])\n",
    "            all_interference_labels.extend([label['interference'] for label in labels])\n",
    "            all_state_labels.extend([label['state'] for label in labels])\n",
    "            all_file_ids.append(data['file_ids'])\n",
    "\n",
    "            del data, batch_features\n",
    "\n",
    "        # Flush to disk periodically\n",
    "        X_memmap.flush()\n",
    "        gc.collect()\n",
    "\n",
    "        print(f\"  Written {write_offset}/{total_samples} samples, RAM: {get_memory_mb():.0f} MB\")\n",
    "\n",
    "    # STEP 4: Final flush (keep memmap, do NOT load into RAM)\n",
    "    X_memmap.flush()\n",
    "    \n",
    "    final_file_ids = np.concatenate(all_file_ids, axis=0)\n",
    "\n",
    "    return {\n",
    "        'X_memmap': X_memmap,  # Return memmap directly\n",
    "        'memmap_file': memmap_file,\n",
    "        'memmap_shape': final_shape,\n",
    "        'y_drone': np.array(all_drone_labels, dtype=np.int32),\n",
    "        'y_interference': np.array(all_interference_labels, dtype=np.int32),\n",
    "        'y_state': np.array(all_state_labels, dtype=np.int32),\n",
    "        'file_ids': final_file_ids\n",
    "    }\n",
    "\n",
    "\n",
    "# Process each pipeline separately (reduces peak memory ~3x)\n",
    "final_data = {}\n",
    "# Process single pipeline\n",
    "print(f\"\\n{'='*60}\")\n",
    "final_data = merge_pipeline_chunked(\n",
    "    \"iq\",\n",
    "    batch_files,\n",
    "    chunk_size=MERGE_CHUNK_SIZE\n",
    ")\n",
    "print(f\"[iq] Shape: {final_data['memmap_shape']}\")\n",
    "print(f\"Memory after iq: {get_memory_mb():.0f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final shapes (memmap-backed):\")\n",
    "# Process single pipeline\n",
    "print(f\"  {pipeline.name}: {final_data['memmap_shape']}\")\n",
    "print(f\"  File IDs: {final_data['file_ids'].shape} (unique: {len(np.unique(final_data['file_ids']))})\")\n",
    "print(f\"Final memory: {get_memory_mb():.0f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Final Features to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features for each pipeline (directly from memmap, no RAM load)\n",
    "print(\"Saving features to npz (streaming from memmap)...\")\n",
    "\n",
    "# Save single pipeline\n",
    "output_file = config.FEATURES_DIR / \"iq_features.npz\"\n",
    "    \n",
    "# Save directly from memmap (npz will read from disk as needed)\n",
    "np.savez_compressed(\n",
    "    output_file,\n",
    "    X=final_data['X_memmap'],  # Memmap array\n",
    "    y_drone=final_data['y_drone'],\n",
    "    y_interference=final_data['y_interference'],\n",
    "    y_state=final_data['y_state'],\n",
    "    file_ids=final_data['file_ids'],\n",
    "    drone_classes=drone_encoder.classes_,\n",
    "    interference_classes=interference_encoder.classes_,\n",
    "    state_classes=state_encoder.classes_,\n",
    "    # Metadata for frequency conversion (baseband to absolute RF)\n",
    "    fs=config.FS,\n",
    "    center_freq=config.CENTER_FREQ,\n",
    "    bandwidth=config.BANDWIDTH\n",
    ")\n",
    "print(f\"Saved iq features to {output_file}\")\n",
    "    \n",
    "# Clean up memmap\n",
    "del final_data['X_memmap']\n",
    "final_data['memmap_file'].unlink()\n",
    "\n",
    "# Free remaining memory\n",
    "del final_data\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nAll features saved successfully! Final RAM: {get_memory_mb():.0f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Saved Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(config.FEATURES_DIR / 'iq_features.npz', 'r') as z:\n",
    "    print(\"Keys in archive:\", z.namelist())\n",
    "    \n",
    "    # Read X shape\n",
    "    with z.open('X.npy') as f:\n",
    "        version = np.lib.format.read_magic(f)\n",
    "        shape, fortran, dtype = np.lib.format._read_array_header(f, version)\n",
    "        print(f\"  X shape: {shape}, dtype: {dtype}\")\n",
    "    \n",
    "    # Read y_drone shape\n",
    "    with z.open('y_drone.npy') as f:\n",
    "        version = np.lib.format.read_magic(f)\n",
    "        shape, fortran, dtype = np.lib.format._read_array_header(f, version)\n",
    "        print(f\"  y_drone shape: {shape}, dtype: {dtype}\")\n",
    "    \n",
    "    # Classes can be loaded (small arrays)\n",
    "    drone_classes = np.load(z.open('drone_classes.npy'), allow_pickle=True)\n",
    "    interference_classes = np.load(z.open('interference_classes.npy'), allow_pickle=True)\n",
    "    state_classes = np.load(z.open('state_classes.npy'), allow_pickle=True)\n",
    "    \n",
    "    print(f\"  Drone classes: {drone_classes}\")\n",
    "    print(f\"  Interference classes: {interference_classes}\")\n",
    "    print(f\"  State classes: {state_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Stratified Train/Test Split with File-Level Grouping\n",
    "\n",
    "### Problem: Temporal Autocorrelation and Data Leakage\n",
    "\n",
    "Each `.dat` file in DroneDetect V2 contains approximately 2 seconds of continuous RF signal sampled at 60 MHz. During preprocessing, this signal is segmented into ~100 overlapping windows of 20ms each.\n",
    "\n",
    "**Critical observation:** Consecutive segments from the same recording exhibit strong temporal autocorrelation. The RF characteristics (carrier frequency drift, hardware imperfections, environmental noise) remain largely constant within a single acquisition.\n",
    "\n",
    "If segments from the same source file appear in both training and test sets, the model may learn to recognize recording-specific artifacts rather than generalizable drone RF signatures. This constitutes **data leakage** and leads to overly optimistic performance estimates that fail to generalize to unseen recordings.\n",
    "\n",
    "### Solution: StratifiedGroupKFold\n",
    "\n",
    "We implement a file-grouped stratified split using `sklearn.model_selection.StratifiedGroupKFold`:\n",
    "\n",
    "1. **Grouping constraint**: All segments from a given `.dat` file are assigned to the same split (train OR test, never both)\n",
    "2. **Stratification**: Splits maintain the drone class distribution to ensure balanced representation\n",
    "3. **Validation**: An assertion verifies zero file overlap between splits\n",
    "\n",
    "This approach ensures that test set performance reflects the model's ability to generalize to entirely new recordings, providing a realistic estimate of real-world deployment accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "\n",
    "def get_stratified_file_split(X, y, file_ids, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data at FILE level to prevent data leakage.\n",
    "    \n",
    "    Segments from the same .dat file (~100 segments) will never appear\n",
    "    in both train and test sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like\n",
    "        Features (n_samples, ...)\n",
    "    y : array-like\n",
    "        Labels for stratification (n_samples,)\n",
    "    file_ids : array-like\n",
    "        Source file ID for each sample (n_samples,)\n",
    "    test_size : float\n",
    "        Approximate test set proportion (actual may vary due to file grouping)\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    train_idx, test_idx : arrays\n",
    "        Indices for train/test split\n",
    "    \"\"\"\n",
    "    n_splits = int(1 / test_size)  # e.g., test_size=0.2 -> 5 splits -> 1 fold = 20%\n",
    "    \n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Take first fold as train/test split\n",
    "    train_idx, test_idx = next(sgkf.split(X, y, groups=file_ids))\n",
    "    \n",
    "    # Verify no file leakage\n",
    "    train_files = set(file_ids[train_idx])\n",
    "    test_files = set(file_ids[test_idx])\n",
    "    assert len(train_files & test_files) == 0, \"Data leakage detected: files in both splits\"\n",
    "    \n",
    "    return train_idx, test_idx\n",
    "\n",
    "\n",
    "# Usage example (run after loading features):\n",
    "# psd_data = np.load(config.FEATURES_DIR / 'iq_features.npz')\n",
    "# X, y, file_ids = psd_data['X'], psd_data['y_drone'], psd_data['file_ids']\n",
    "# train_idx, test_idx = get_stratified_file_split(X, y, file_ids)\n",
    "# X_train, X_test = X[train_idx], X[test_idx]\n",
    "# y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "print(\"Split function defined: get_stratified_file_split(X, y, file_ids, test_size=0.2)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
