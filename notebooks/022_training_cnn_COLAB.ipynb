{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aeVDThGoznE"
   },
   "source": [
    "# DroneDetect V2 - CNN Classification (Google Colab)\n",
    "\n",
    "Train CNN classifiers on spectrogram features:\n",
    "- VGG16 (frozen features + trainable FC)\n",
    "- ResNet50 (frozen features + trainable FC)\n",
    "- File-level stratified split to prevent data leakage\n",
    "- Side-by-side performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4g-hftcoznJ"
   },
   "source": [
    "## 1. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JS2D9O6LoznK",
    "outputId": "700fd087-7567-4bf1-d3f2-ebdfefaf06d6"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKTZNdFnoznL"
   },
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGGOuWbXn7wT",
    "outputId": "d9f46385-b3ce-4c13-869c-6eabe558748c"
   },
   "outputs": [],
   "source": [
    "!pip install -U kaleido==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zd4AcFPqoznM",
    "outputId": "4d0e39f9-277c-46bc-be20-172e304a3834"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import torchvision.models as tv_models\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Figure saving configuration\n",
    "NOTEBOOK_NAME = \"training_cnn_COLAB\"\n",
    "FIGURES_DIR = Path(\"figures\") / NOTEBOOK_NAME\n",
    "\n",
    "\n",
    "def save_figure(fig) -> None:\n",
    "    \"\"\"Save plotly figure to PNG file using the figure's title as filename.\"\"\"\n",
    "    FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    title = fig.layout.title.text if fig.layout.title.text else \"untitled\"\n",
    "    filename = re.sub(r'[^\\w\\s-]', '', title).strip()\n",
    "    filename = re.sub(r'[\\s-]+', '_', filename)\n",
    "    filepath = FIGURES_DIR / f\"{filename}.png\"\n",
    "    try:\n",
    "        fig.write_image(str(filepath), width=1200, height=800)\n",
    "        print(f\"Saved: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save figure (kaleido required): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejBP-131oznM"
   },
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HLdiXy1oznN",
    "outputId": "a90d260b-83e6-4dc9-da1a-74e0d63ae0e4"
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # Paths\n",
    "    'features_path': 'drive/MyDrive/DroneDetect_V2/output/features/spectrogram_features.npz',\n",
    "    'models_dir': 'drive/MyDrive/DroneDetect_V2/output/models/',\n",
    "    'test_data_dir': 'drive/MyDrive/DroneDetect_V2/output/sample/test_data/',\n",
    "\n",
    "    # Split parameters\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 42,\n",
    "\n",
    "    # Training parameters\n",
    "    'batch_size': 128,\n",
    "    'epochs': 10,\n",
    "    'learning_rate': 0.01,\n",
    "\n",
    "    # Device\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "print(f\"Configuration: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9bEXITdoznN"
   },
   "source": [
    "## 4. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HH6mN3eIoznO",
    "outputId": "87b161d3-d557-47cb-b77c-fc77d1b676a0"
   },
   "outputs": [],
   "source": [
    "class VGG16FC(nn.Module):\n",
    "    \"\"\"VGG16 with frozen features and trainable classifier.\n",
    "\n",
    "    This model uses a pre-trained VGG16 backbone with weights frozen,\n",
    "    replacing the classifier with a new fully connected layer for the\n",
    "    specific number of classes.\n",
    "\n",
    "    Attributes:\n",
    "        features (nn.Sequential): The feature extractor part of VGG16.\n",
    "        classifier (nn.Linear): The trainable classification layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int):\n",
    "        \"\"\"Initializes VGG16FC.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): The number of output classes for classification.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Removed from_array logic as inputs are strictly RGB\n",
    "\n",
    "        vgg = tv_models.vgg16(weights='IMAGENET1K_V1')\n",
    "        self.features = nn.Sequential(*list(vgg.children())[:-1])\n",
    "\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Linear(25088, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the model.\n",
    "\n",
    "        Handles input permutation from NHWC to NCHW format if necessary.\n",
    "\n",
    "        - NHWC: (Batch, Height, Width, Channels) - Common in NumPy/OpenCV.\n",
    "        - NCHW: (Batch, Channels, Height, Width) - Standard for PyTorch.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor. Shape can be (N, H, W, C) or (N, C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Model logits.\n",
    "        \"\"\"\n",
    "        # Handle RGB inputs: NHWC -> NCHW\n",
    "        if x.dim() == 4 and x.shape[-1] == 3:\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x = self.features(x)\n",
    "        # Use flatten(1) to handle non-contiguous tensors and flatten starting from batch dim\n",
    "        x = x.flatten(1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def reset_weights(self):\n",
    "        \"\"\"Resets the weights of the classifier layer.\"\"\"\n",
    "        self.classifier.reset_parameters()\n",
    "\n",
    "\n",
    "class ResNet50FC(nn.Module):\n",
    "    \"\"\"ResNet50 with frozen features and trainable classifier.\n",
    "\n",
    "    This model uses a pre-trained ResNet50 backbone with weights frozen.\n",
    "    The final fully connected layer and adaptive pooling are removed and\n",
    "    replaced with a new linear classifier.\n",
    "\n",
    "    Attributes:\n",
    "        features (nn.Sequential): The feature extractor part of ResNet50.\n",
    "        classifier (nn.Linear): The trainable classification layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int):\n",
    "        \"\"\"Initializes ResNet50FC.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): The number of output classes for classification.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        resnet = tv_models.resnet50(weights='IMAGENET1K_V1')\n",
    "        # Remove FC and adaptive pooling\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
    "\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Output of ResNet50 before pooling: 2048 x 7 x 7 = 100352\n",
    "        self.classifier = nn.Linear(100352, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the model.\n",
    "\n",
    "        Handles input permutation from NHWC to NCHW format if necessary.\n",
    "\n",
    "        - NHWC: (Batch, Height, Width, Channels) - Common in NumPy/OpenCV.\n",
    "        - NCHW: (Batch, Channels, Height, Width) - Standard for PyTorch.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor. Shape can be (N, H, W, C) or (N, C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Model logits.\n",
    "        \"\"\"\n",
    "        if x.dim() == 4 and x.shape[-1] == 3:\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x = self.features(x)\n",
    "        # Use flatten(1) to handle non-contiguous tensors and flatten starting from batch dim\n",
    "        x = x.flatten(1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def reset_weights(self):\n",
    "        \"\"\"Resets the weights of the classifier layer.\"\"\"\n",
    "        self.classifier.reset_parameters()\n",
    "\n",
    "print(\"Model classes defined (VGG16FC, ResNet50FC)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCOWaDqdoznO"
   },
   "source": [
    "## 4b. Memory-Efficient Dataset\n",
    "\n",
    "**Problem**: Spectrogram NPZ file is 11.73 GB (19478 samples x 224x224x3 x 4 bytes).\n",
    "Using fancy indexing `X_train = X[train_idx]` on a memory-mapped array forces NumPy\n",
    "to load the entire subset into RAM, causing OOM on Colab.\n",
    "\n",
    "**Solution**: Custom `RGBMemmapDataset` that stores indices and loads one sample\n",
    "at a time via `__getitem__`. The `.copy()` call breaks the memmap view and loads\n",
    "only the requested sample.\n",
    "\n",
    "**Memory savings**: 11.73 GB upfront load â†’ ~77 MB per batch (128 samples) + 2 GB PyTorch overhead.\n",
    "Total RAM usage: < 5 GB vs 11.73 GB.\n",
    "\n",
    "**Trade-off**: Disk I/O overhead (~10-20s per epoch), but prevents OOM crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xr2RLLg3oznP",
    "outputId": "9aac8f52-31e3-4911-d47b-601373fae31d"
   },
   "outputs": [],
   "source": [
    "class RGBMemmapDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Memory-efficient dataset for memmap RGB spectrograms.\n",
    "\n",
    "    Loads one sample at a time from disk instead of loading entire array into RAM.\n",
    "\n",
    "    Memory optimization: Avoids fancy indexing on memmap which would load\n",
    "    entire subset into RAM (11.73 GB). Instead, stores indices and loads\n",
    "    samples individually via __getitem__.\n",
    "\n",
    "    Memory usage: ~77 MB per batch (128 samples) vs 11.73 GB upfront.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    memmap_array : np.memmap\n",
    "        Memory-mapped array from np.load(..., mmap_mode='r')\n",
    "    indices : np.ndarray\n",
    "        Indices for this split (train or test)\n",
    "    labels : np.ndarray\n",
    "        Labels for samples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, memmap_array, indices, labels):\n",
    "        self.memmap = memmap_array\n",
    "        self.indices = indices\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Map dataset index to original array index\n",
    "        actual_idx = self.indices[idx]\n",
    "        # CRITICAL: .copy() breaks memmap view and loads single sample\n",
    "        rgb = self.memmap[actual_idx].copy()  # (224, 224, 3)\n",
    "\n",
    "        # Convert to tensor\n",
    "        x = torch.from_numpy(rgb).float()\n",
    "        y_label = torch.tensor(self.labels[idx]).long()\n",
    "\n",
    "        return x, y_label\n",
    "\n",
    "print(\"Memory-efficient RGBMemmapDataset class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ4gKcf_oznP"
   },
   "source": [
    "## 5. File-Level Stratified Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RR_1QMkzoznQ",
    "outputId": "6d92e710-b504-4625-c6cb-0b1e0a4c6e2d"
   },
   "outputs": [],
   "source": [
    "def get_stratified_file_split(X, y, file_ids, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data at FILE level to prevent data leakage.\n",
    "\n",
    "    Segments from the same .dat file (~100 segments) will never appear\n",
    "    in both train and test sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like\n",
    "        Features (n_samples, ...)\n",
    "    y : array-like\n",
    "        Labels for stratification (n_samples,)\n",
    "    file_ids : array-like\n",
    "        Source file ID for each sample (n_samples,)\n",
    "    test_size : float\n",
    "        Approximate test set proportion (actual may vary due to file grouping)\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_idx, test_idx : arrays\n",
    "        Indices for train/test split\n",
    "    \"\"\"\n",
    "    n_splits = int(1 / test_size)  # e.g., test_size=0.2 -> 5 splits -> 1 fold = 20%\n",
    "\n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Take first fold as train/test split\n",
    "    train_idx, test_idx = next(sgkf.split(X, y, groups=file_ids))\n",
    "\n",
    "    # Verify no file leakage\n",
    "    train_files = set(file_ids[train_idx])\n",
    "    test_files = set(file_ids[test_idx])\n",
    "    assert len(train_files & test_files) == 0, \"Data leakage detected: files in both splits\"\n",
    "\n",
    "    return train_idx, test_idx\n",
    "\n",
    "print(\"Split function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgfVvUFIoznQ"
   },
   "source": [
    "## 6. Streaming Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7jTxKXCuoznR",
    "outputId": "828bbf6d-b24e-4198-9640-27947a8619c7"
   },
   "outputs": [],
   "source": [
    "# Memory optimization: use memory mapping to avoid loading full array\n",
    "data = np.load(CONFIG['features_path'], mmap_mode='r', allow_pickle=True)\n",
    "\n",
    "X_memmap = data['X']  # Shape: (N, 224, 224, 3) - memory mapped, not loaded\n",
    "y_drone = data['y_drone'][:]  # Load labels (small, ~76 KB)\n",
    "y_interference = data['y_interference'][:]\n",
    "y_state = data['y_state'][:]\n",
    "file_ids = data['file_ids'][:]  # Load file IDs (small, ~76 KB)\n",
    "drone_classes = data['drone_classes']\n",
    "interference_classes = data['interference_classes']\n",
    "state_classes = data['state_classes']\n",
    "\n",
    "print(f\"Spectrograms shape: {X_memmap.shape}\")\n",
    "print(f\"Labels shape: {y_drone.shape}\")\n",
    "print(f\"File IDs shape: {file_ids.shape} (unique files: {len(np.unique(file_ids))})\")\n",
    "print(f\"Drone classes: {drone_classes}\")\n",
    "print(f\"Interference classes: {interference_classes}\")\n",
    "print(f\"State classes: {state_classes}\")\n",
    "print(f\"Number of classes: {len(drone_classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raKblHEyoznR"
   },
   "source": [
    "## 7. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BR7MuxeRoznR",
    "outputId": "da293a69-3b58-4a4c-8e2b-e44396b66fda"
   },
   "outputs": [],
   "source": [
    "print(\"Performing file-level stratified split...\")\n",
    "train_idx, test_idx = get_stratified_file_split(\n",
    "    X_memmap, y_drone, file_ids,\n",
    "    test_size=CONFIG['test_size'],\n",
    "    random_state=CONFIG['random_state']\n",
    ")\n",
    "\n",
    "# Split labels only (X handled by RGBMemmapDataset)\n",
    "y_train = y_drone[train_idx]\n",
    "y_test = y_drone[test_idx]\n",
    "y_interference_test = y_interference[test_idx]\n",
    "y_state_test = y_state[test_idx]\n",
    "\n",
    "print(f\"Train set: {len(train_idx)} samples\")\n",
    "print(f\"Test set: {len(test_idx)} samples\")\n",
    "print(f\"Train class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test class distribution: {np.bincount(y_test)}\")\n",
    "print(f\"\\nMemory saved: Indices stored instead of 11.73 GB array copy\")\n",
    "\n",
    "# Save test data for reuse\n",
    "test_data_dir = CONFIG['test_data_dir']\n",
    "os.makedirs(test_data_dir, exist_ok=True)\n",
    "\n",
    "# Load full test set into memory from memmap\n",
    "print(\"\\nLoading test set into memory for saving...\")\n",
    "X_test = X_memmap[test_idx].copy()\n",
    "\n",
    "# Save full test data\n",
    "test_data_path = os.path.join(test_data_dir, 'cnn_test_data.npz')\n",
    "np.savez(\n",
    "    test_data_path,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    y_interference_test=y_interference_test,\n",
    "    y_state_test=y_state_test,\n",
    "    test_idx=test_idx,\n",
    "    file_ids_test=file_ids[test_idx],\n",
    "    drone_classes=drone_classes,\n",
    "    interference_classes=interference_classes,\n",
    "    state_classes=state_classes\n",
    ")\n",
    "print(f\"Full test data saved to {test_data_path}\")\n",
    "\n",
    "# Save separated files per Drone and Interference (Hierarchical)\n",
    "print(\"\\nGenerating separated test files (structure: spectrogram/INT/DRONE/)...\")\n",
    "\n",
    "for d_idx, drone_class in enumerate(drone_classes):\n",
    "    for i_idx, int_class in enumerate(interference_classes):\n",
    "        # Filter for specific drone and interference\n",
    "        mask = (y_test == d_idx) & (y_interference_test == i_idx)\n",
    "\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "\n",
    "        X_sub = X_test[mask]\n",
    "        y_sub = y_test[mask]\n",
    "        y_int_sub = y_interference_test[mask]\n",
    "\n",
    "        # Define components for hierarchy and filename\n",
    "        data_type = 'spectrogram'\n",
    "        int_name = str(int_class)\n",
    "        drone_name = str(drone_class)\n",
    "        dims = \"224x224x3\"\n",
    "\n",
    "        # Create directory structure: output/test_data/{INT}/\n",
    "        save_dir = os.path.join(test_data_dir, int_name)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Construct filename: spectrogram_{INT}_{DRONE}_224x224x3.npz\n",
    "        filename = f\"{data_type}_{int_name}_{drone_name}_{dims}.npz\"\n",
    "        file_path = os.path.join(save_dir, filename)\n",
    "\n",
    "        np.savez(\n",
    "            file_path,\n",
    "            X=X_sub,\n",
    "            y=y_sub,\n",
    "            y_interference=y_int_sub,\n",
    "            drone_class=drone_class,\n",
    "            interference_class=int_class\n",
    "        )\n",
    "        print(f\"  Saved {filename} in {save_dir} ({len(X_sub)} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTCOe90roznR"
   },
   "source": [
    "## 8. Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kfosyO7oznR",
    "outputId": "3b5d7d53-c9af-460b-8a42-fa4390d2e788"
   },
   "outputs": [],
   "source": [
    "train_dataset = RGBMemmapDataset(X_memmap, train_idx, y_train)\n",
    "test_dataset = RGBMemmapDataset(X_memmap, test_idx, y_test)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "print(f\"Memory per batch: ~{CONFIG['batch_size'] * 224 * 224 * 3 * 4 / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhoMTu1WoznS"
   },
   "source": [
    "## 8b. Memory Profiling Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wom48-6zoznS",
    "outputId": "1b0bc2c1-d99a-4dc3-fab9-cc345c21e706"
   },
   "outputs": [],
   "source": [
    "process = psutil.Process()\n",
    "mem_info = process.memory_info()\n",
    "print(f\"Memory usage: {mem_info.rss / 1024**3:.2f} GB\")\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU memory reserved: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nstg6PW6oznS"
   },
   "source": [
    "## 9. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOnVVbEkoznT",
    "outputId": "03d1f553-5f8f-449d-ed45-78c70896294d"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, epochs=10, lr=0.01, device='cuda'):\n",
    "    \"\"\"\n",
    "    Train a PyTorch model with memory cleanup.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        Model to train\n",
    "    train_loader : DataLoader\n",
    "        Training data loader\n",
    "    test_loader : DataLoader\n",
    "        Test data loader\n",
    "    epochs : int\n",
    "        Number of epochs\n",
    "    lr : float\n",
    "        Learning rate\n",
    "    device : str\n",
    "        Device to use ('cuda' or 'cpu')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : nn.Module\n",
    "        Trained model\n",
    "    history : dict\n",
    "        Training history\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for batch_X, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += batch_y.size(0)\n",
    "            train_correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in test_loader:\n",
    "                batch_X = batch_X.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += batch_y.size(0)\n",
    "                test_correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "        # Record history\n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['train_acc'].append(100 * train_correct / train_total)\n",
    "        history['test_loss'].append(test_loss / len(test_loader))\n",
    "        history['test_acc'].append(100 * test_correct / test_total)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "              f\"Train Loss: {history['train_loss'][-1]:.4f}, \"\n",
    "              f\"Train Acc: {history['train_acc'][-1]:.2f}%, \"\n",
    "              f\"Test Loss: {history['test_loss'][-1]:.4f}, \"\n",
    "              f\"Test Acc: {history['test_acc'][-1]:.2f}%\")\n",
    "\n",
    "        # Memory cleanup after each epoch\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return model, history\n",
    "\n",
    "print(\"Training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoWCv_hDoznT"
   },
   "source": [
    "## 10. Train VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec2HhCQ5oznT",
    "outputId": "18b76ae8-0a6e-4ced-98e9-c72fed44a6ef"
   },
   "outputs": [],
   "source": [
    "num_classes = len(drone_classes)\n",
    "vgg_model = VGG16FC(num_classes=num_classes)\n",
    "\n",
    "print(f\"Training VGG16 with {num_classes} classes...\")\n",
    "vgg_model, vgg_history = train_model(\n",
    "    vgg_model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "print(\"VGG16 training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ul7mX1FzoznT"
   },
   "source": [
    "## 11. VGG16 Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IplaJ1nGoznT",
    "outputId": "c0051c35-d9f9-4cab-f05e-4c94aabaab08"
   },
   "outputs": [],
   "source": [
    "vgg_model.eval()\n",
    "vgg_preds = []\n",
    "vgg_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(CONFIG['device'])\n",
    "        outputs = vgg_model(batch_X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        vgg_preds.extend(predicted.cpu().numpy())\n",
    "        vgg_true.extend(batch_y.numpy())\n",
    "\n",
    "vgg_preds = np.array(vgg_preds)\n",
    "vgg_true = np.array(vgg_true)\n",
    "\n",
    "print(\"VGG16 Classification Report:\")\n",
    "print(classification_report(vgg_true, vgg_preds, target_names=drone_classes))\n",
    "print(f\"\\nVGG16 Accuracy: {accuracy_score(vgg_true, vgg_preds):.4f}\")\n",
    "print(f\"VGG16 F1 Score (macro): {f1_score(vgg_true, vgg_preds, average='macro'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOMmukBooznT"
   },
   "source": [
    "## 12. VGG16 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "5RXVHOk8oznT",
    "outputId": "dfc1091d-7819-4b33-dcf0-a9dbbd2c5712"
   },
   "outputs": [],
   "source": [
    "cm_vgg = confusion_matrix(vgg_true, vgg_preds)\n",
    "\n",
    "# Create confusion matrix heatmap with plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=cm_vgg,\n",
    "    x=list(drone_classes),\n",
    "    y=list(drone_classes),\n",
    "    colorscale='Blues',\n",
    "    text=cm_vgg,\n",
    "    texttemplate='%{text}',\n",
    "    textfont={'size': 12},\n",
    "    hoverongaps=False\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='VGG16 Confusion Matrix',\n",
    "    xaxis_title='Predicted Label',\n",
    "    yaxis_title='True Label',\n",
    "    xaxis={'side': 'bottom'},\n",
    "    yaxis={'autorange': 'reversed'},\n",
    "    width=800,\n",
    "    height=700\n",
    ")\n",
    "fig.show()\n",
    "save_figure(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89MKe9LPoznU"
   },
   "source": [
    "## 13. Train ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99P-1u3QoznU",
    "outputId": "7604aefa-6b8d-42fd-e1e6-7b7be0d87f9a"
   },
   "outputs": [],
   "source": [
    "num_classes = len(drone_classes)\n",
    "resnet_model = ResNet50FC(num_classes=num_classes)\n",
    "\n",
    "print(f\"Training ResNet50 with {num_classes} classes...\")\n",
    "resnet_model, resnet_history = train_model(\n",
    "    resnet_model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "print(\"ResNet50 training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G24moAedoznU"
   },
   "source": [
    "## 14. ResNet50 Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-R460mcVoznU",
    "outputId": "a9b9a9db-c94e-4817-e3fd-a5f3ff8a76e5"
   },
   "outputs": [],
   "source": [
    "resnet_model.eval()\n",
    "resnet_preds = []\n",
    "resnet_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(CONFIG['device'])\n",
    "        outputs = resnet_model(batch_X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        resnet_preds.extend(predicted.cpu().numpy())\n",
    "        resnet_true.extend(batch_y.numpy())\n",
    "\n",
    "resnet_preds = np.array(resnet_preds)\n",
    "resnet_true = np.array(resnet_true)\n",
    "\n",
    "print(\"ResNet50 Classification Report:\")\n",
    "print(classification_report(resnet_true, resnet_preds, target_names=drone_classes))\n",
    "print(f\"\\nResNet50 Accuracy: {accuracy_score(resnet_true, resnet_preds):.4f}\")\n",
    "print(f\"ResNet50 F1 Score (macro): {f1_score(resnet_true, resnet_preds, average='macro'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhOWmf-xoznU"
   },
   "source": [
    "## 15. ResNet50 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "btQqivvioznU",
    "outputId": "ad412ed1-d7fe-4ac5-9b46-bd042542257f"
   },
   "outputs": [],
   "source": [
    "cm_resnet = confusion_matrix(resnet_true, resnet_preds)\n",
    "\n",
    "# Create confusion matrix heatmap with plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=cm_resnet,\n",
    "    x=list(drone_classes),\n",
    "    y=list(drone_classes),\n",
    "    colorscale='Greens',\n",
    "    text=cm_resnet,\n",
    "    texttemplate='%{text}',\n",
    "    textfont={'size': 12},\n",
    "    hoverongaps=False\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ResNet50 Confusion Matrix',\n",
    "    xaxis_title='Predicted Label',\n",
    "    yaxis_title='True Label',\n",
    "    xaxis={'side': 'bottom'},\n",
    "    yaxis={'autorange': 'reversed'},\n",
    "    width=800,\n",
    "    height=700\n",
    ")\n",
    "fig.show()\n",
    "save_figure(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eWci7yVoznU"
   },
   "source": [
    "## 16. Side-by-Side Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "vdiB_fyfoznU",
    "outputId": "5a0107ab-c8c8-4f38-8010-c85250d3e766"
   },
   "outputs": [],
   "source": [
    "# Training curves comparison\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('Training History Comparison', 'Final Performance Comparison'))\n",
    "\n",
    "# Training curves\n",
    "epochs = list(range(1, len(vgg_history['train_acc']) + 1))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=epochs, y=vgg_history['train_acc'], mode='lines+markers', name='VGG16 Train', line=dict(color='blue')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=epochs, y=vgg_history['test_acc'], mode='lines+markers', name='VGG16 Test', line=dict(color='blue', dash='dash')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=epochs, y=resnet_history['train_acc'], mode='lines+markers', name='ResNet50 Train', line=dict(color='green')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=epochs, y=resnet_history['test_acc'], mode='lines+markers', name='ResNet50 Test', line=dict(color='green', dash='dash')), row=1, col=1)\n",
    "\n",
    "# Final metrics comparison\n",
    "models = ['VGG16', 'ResNet50']\n",
    "accuracies = [accuracy_score(vgg_true, vgg_preds), accuracy_score(resnet_true, resnet_preds)]\n",
    "f1_scores = [f1_score(vgg_true, vgg_preds, average='macro'), f1_score(resnet_true, resnet_preds, average='macro')]\n",
    "\n",
    "fig.add_trace(go.Bar(x=models, y=accuracies, name='Accuracy', marker_color='steelblue'), row=1, col=2)\n",
    "fig.add_trace(go.Bar(x=models, y=f1_scores, name='F1 Score (macro)', marker_color='coral'), row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='CNN Training Comparison - VGG16 vs ResNet50',\n",
    "    height=500,\n",
    "    width=1200,\n",
    "    barmode='group'\n",
    ")\n",
    "fig.update_xaxes(title_text='Epoch', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Accuracy (%)', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Model', row=1, col=2)\n",
    "fig.update_yaxes(title_text='Score', row=1, col=2)\n",
    "\n",
    "fig.show()\n",
    "save_figure(fig)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"VGG16    - Accuracy: {accuracies[0]:.4f}, F1: {f1_scores[0]:.4f}\")\n",
    "print(f\"ResNet50 - Accuracy: {accuracies[1]:.4f}, F1: {f1_scores[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgjBYGU9oznV"
   },
   "source": [
    "## 17. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-3VwLH6oznj",
    "outputId": "6e3dc143-d0d0-4d47-da42-58f061b161fc"
   },
   "outputs": [],
   "source": [
    "os.makedirs(CONFIG['models_dir'], exist_ok=True)\n",
    "\n",
    "# Save VGG16\n",
    "vgg_path = os.path.join(CONFIG['models_dir'], 'vgg16_cnn.pth')\n",
    "torch.save({\n",
    "    'model_state_dict': vgg_model.state_dict(),\n",
    "    'history': vgg_history,\n",
    "    'num_classes': num_classes,\n",
    "    'drone_classes': drone_classes\n",
    "}, vgg_path)\n",
    "print(f\"VGG16 model saved to {vgg_path}\")\n",
    "\n",
    "# Save ResNet50\n",
    "resnet_path = os.path.join(CONFIG['models_dir'], 'resnet50_cnn.pth')\n",
    "torch.save({\n",
    "    'model_state_dict': resnet_model.state_dict(),\n",
    "    'history': resnet_history,\n",
    "    'num_classes': num_classes,\n",
    "    'drone_classes': drone_classes\n",
    "}, resnet_path)\n",
    "print(f\"ResNet50 model saved to {resnet_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtFpIeiAoznj"
   },
   "source": [
    "## 18. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jm7-C3c4oznj",
    "outputId": "6ec59fae-779d-4414-ad40-b7d3d692a931"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CNN TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nDataset: {len(y_drone)} total | {len(y_train)} train | {len(y_test)} test | {num_classes} classes\")\n",
    "print(f\"Training: {CONFIG['epochs']} epochs, batch_size={CONFIG['batch_size']}, lr={CONFIG['learning_rate']}, device={CONFIG['device']}\")\n",
    "\n",
    "print(f\"\\nVGG16: Accuracy={accuracy_score(vgg_true, vgg_preds):.4f}, F1={f1_score(vgg_true, vgg_preds, average='macro'):.4f}\")\n",
    "print(f\"ResNet50: Accuracy={accuracy_score(resnet_true, resnet_preds):.4f}, F1={f1_score(resnet_true, resnet_preds, average='macro'):.4f}\")\n",
    "\n",
    "print(f\"\\nModels saved to: {CONFIG['models_dir']}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
